{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de colisiones - DEMO\n",
    "\n",
    "En este cuaderno se utilizará un modelo de machine-learning entrenado previamente para detectar si el JetBot se encuentra libre o bloqueado. Esto nos permitirá implementar la lógica que impida que el JetBot evite colisiones.\n",
    "\n",
    "## Cargar el modelo preentrenado\n",
    "\n",
    "El modelo a utilizar se debe encontrar en el mismo directorio de los ``notebooks``, con nombre ``best_model.pth``. Existen cuadernos adicionales con información sobre como entrenar este modelo desde cero. Es posible importar ficheros desde la propia interfaz de Jupyter.\n",
    "\n",
    "> Asegurarse de que el fichero se ha importado antes de ejecutar las celdas siguientes.\n",
    "\n",
    "La siguiente celda inicializa el modelo utilizando la librería PyTorch. PyTorch es un framework de machine learning que permite el entrenamiento y manipulación de modelos. En clases posteriores se profundizará en estos conceptos, la práctica actual está centrada en la utilización de un modelo previo que nos permita implementar nuevos comportamientos en el JetBot a partir de sus resultados.\n",
    "\n",
    "Para simplificar, podemos considerar el modelo como una función que toma como entrada imágenes extraídas de la cámara y produce un resultado 'Bloqueado' o 'Libre', a partir de unos parámetros de configuración conocidos como ``pesos`` que son calculados en tiempo de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, cargar los pesos del fichero ``best_model.pth`` que acabamos de importar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualmente los pesos del modelo se encuentran en la memoria de la CPU. La siguiente celda realiza una transferencia del modelo a la memoria de la GPU, mucho más rápida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de preprocesado\n",
    "El formato en el que fue entrenado el modelo no se corresponde exactamente con el formato de imágenes de la cámara, por lo que es necesario implementar una función de preprocesado que realice las siguientes transformaciones:\n",
    "\n",
    "1. Transformación de BGR a RGB\n",
    "2. Conversión de representación HWC a CHW \n",
    "3. Normalizar utilizando los parámetros que se utilizaron en tiempo de entrenamiento (la cámara proporciona valores en el rango [0, 255] y las imágenes de entrenamiento en el rango [0,1], por lo que realizará un escalado de 255).\n",
    "4. Transferencia de datos entre CPU y GPU\n",
    "5. Añadir dimensión adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya se ha definido la función de preprocesamiento que convierte imágenes del formato de la cámara al formato de entrada de la red neuronal.\n",
    "\n",
    "La siguiente celda muestra la cámara del JetBot y un slider que muestra la probabilidad de que el JetBot se encuentre bloqueado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea una instancia del robot que nos permitirá interactuar con los motores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se creará una función que será invocada cada vez que el valor de la cámara cambia. Esta función realizará los siguientes pasos:\n",
    "\n",
    "1. Preprocesar la imagen de la cámara\n",
    "2. Ejecutar red neuronal\n",
    "3. Mientras la salida de la red neuronal indique que existe un bloqueo, se girará a la izquierda. En caso contrario se avanzará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # normalizar el vector de la red neuronal de manera que sume 1 (distribución de probabilidad)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(0.4)\n",
    "    else:\n",
    "        robot.left(0.4)\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # se invoca la primera vez para inicializar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida la función, es necesario asociarla a la cámara del JetBot para su utilización. Podemos realizarlo con la función ``observe``\n",
    "\n",
    "> OJO: La siguiente celda hará que el JetBot se mueva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # asocia la función 'update' con la variable 'value' de la cámara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Jetbot debería estar ejecutando acciones con cada frame de la cámara. Comprobar el correcto funcionamiento poniendo obstáculos en su camino. También debería detectar como bloqueo cuando se puede caer de la mesa.\n",
    "\n",
    "Para detener este funcionamiento, es posible desconectar nuestra función de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "El presente cuaderno muestra un ejemplo de como utilizar los resultados de un modelo machine learning  pre-entrenado para implementar nueva lógica en el comportamiento del robot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
